I built a tool that tells you how hard a website is to scrape
Showcase
UPDATE:
Website is now live!

Try it now: https://www.caniscrape.org

- No installation required

- Instant analysis

- Same comprehensive checks as the CLI

NOTE:
I haven't added the flag capabilities yet so its just the default scan. Its also still one link at a time, so all the great ideas I've received for the website will come soon (I'm gonna keep working on it). It'll take about 1-3 days but ill make it a lot better for the V1.0.0 release.

CLI still available on GitHub for those who prefer it.

Hi everyone,
I made a Python package called caniscrape that analyzes any website's anti-bot protections before you start scraping.

It tells you what you're up against (Cloudflare, rate limits, JavaScript rendering, CAPTCHAs, TLS fingerprinting, honeypots) and gives you a difficulty score + specific recommendations.

What My Project Does
caniscrape checks a website for common anti-bot mechanisms and reports:

A difficulty score (0‚Äì10)

Which protections are active (e.g., Cloudflare, Akamai, hCaptcha, etc.)

What tools you‚Äôll likely need (headless browsers, proxies, CAPTCHA solvers, etc.)

Whether using a scraping API might be better

This helps you decide the right scraping approach before you waste time building a bot that keeps getting blocked.

Target Audience
Web scrapers, data engineers, and researchers who deal with protected or dynamic websites

Developers who want to test bot-detection systems or analyze site defenses

Hobbyists learning about anti-bot tech and detection methods

It‚Äôs not a bypassing or cracking tool ‚Äî it‚Äôs for diagnostics and awareness.

Comparison
Unlike tools like WAFW00F or WhatWaf, which only detect web application firewalls,
caniscrape runs multi-layered tests:

Simulates browser and bot requests (via Playwright)

Detects rate limits, JavaScript challenges, and honeypot traps

Scores site difficulty based on detection layers

Suggests scraping strategies or alternative services

So it‚Äôs more of a pre-scrape analysis toolkit, not just a WAF detector.

Installation
pip install caniscrape
Quick setup (required):

playwright install chromium  # Download browser
pipx install wafw00f         # WAF detection
Example Usage
caniscrape https://example.com
Output includes:

Difficulty score (0‚Äì10)

Active protections

Recommended tools/approach

ADVICE:
Results can vary between runs because bot protections adapt dynamically.
Some heavy-protection sites (like Amazon) may produce these varied results. Of course, this will improve over time, but running the command multiple times can mitigate this.

GitHub
https://github.com/ZA1815/caniscrape


Upvote
532

Downvote

52
Go to comments


Share
u/data_tinkerer avatar
data_tinkerer
‚Ä¢
Promoted

Stay Up to Date on Data Engineering - For Free
Learn More
datatinkerer.io
Thumbnail image: Stay Up to Date on Data Engineering - For Free
Join the conversation
Sort by:

Best

Search Comments
Expand comment search
Comments Section
AustinWitherspoon
‚Ä¢
2mo ago
Honestly a website seems like a better fit for this. I'm way more likely to try going to your website and copying and pasting a url into a box than I am to pip install and run unknown code on my machine

And then you could have some ads on the site for a small amount of extra money



Upvote
317

Downvote

Reply

Award

Share

prashnts
‚Ä¢
2mo ago
There's value in having a local tool. It answers how hard is it for me to scrape it, vs the website servers - accounting for my country/isp etc.


Upvote
102

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Yeah that‚Äôs a good idea, I did the CLI first as popular scrapers like Scrapy work in the terminal as well, so I just thought it‚Äôd be easier. If others have the same suggestion as you, I‚Äôll start working on a website right away



Upvote
58

Downvote

Reply

Award

Share

u/manufactured_narwhal avatar
manufactured_narwhal
‚Ä¢
2mo ago
judging by upvotes, many others have the same suggestion!



Upvote
11

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Already started lmao


Upvote
18

Downvote

Reply

Award

Share

Achrus
‚Ä¢
2mo ago
I agree, a website would be nice, but if it‚Äôs only a few websites then it‚Äôs not too bad to figure out yourself. There are times where a stakeholder may give you an excel sheet with 100s of domains to scrape and it‚Äôs a pain figuring out the little nuances of each one. Filtering that list into easy, medium, and hard is a quick way to show a PM impact and blockers.



Upvote
8

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
In a future update I‚Äôll definitely add a way to paste a bunch of links (or import an Excel/CSV file on a website) and return it in a easy to read format, I know that‚Äôs one of the biggest blockers I have right now. Pasting a bunch of links at once and running them all at the same time would save a crazy amount of time


Upvote
9

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
‚Ä¢
Edited 2mo ago
https://www.caniscrape.org/

Alright here's the website. Its really a minimum valuable product lmao cuz I just wanted to get it out there for those who didn't wanna download it directly. I haven't added the flag capabilities yet so its just the default scan. Its also still one link at a time, so all the great ideas I've received for the website will come soon (I'm gonna keep working on it). It'll take about 1-3 days but ill make it a lot better for the V1.0.0 release.


Upvote
3

Downvote

Reply

Award

Share

u/lukerm_zl avatar
lukerm_zl
‚Ä¢
2mo ago
Cool idea!

How does it figure out rate limiting? Do you hit websites multiple times?



Upvote
14

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
I do 4 probe requests first (just single requests but four in a row) and then I do 8 requests in a burst. The burst is low for more advanced websites that don‚Äôt really check rate limiting but request volume, so I‚Äôll likely add a flag that lets you set burst request size to make it more adaptable. And thanks!


Upvote
13

Downvote

Reply

Award

Share

Marimoh
‚Ä¢
2mo ago
Sounds cool! I‚Äôll check it out


Upvote
9

Downvote

Reply

Award

Share

u/Anlatan avatar
u/Anlatan
‚Ä¢
Promoted

Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
Bring your ideas to life effortlessly.
novelai.net
Learn More
forgetfulAlways
‚Ä¢
2mo ago
Maybe you just haven‚Äôt mentioned it but shouldn‚Äôt the first point of call for a web scraping analyser be looking at robots.txt. Unless the goal is to intentionally disregard it



Upvote
11

Downvote

Reply

Award

Share

u/im_made_of_jam avatar
im_made_of_jam
‚Ä¢
2mo ago
Since websites that care usually set up some form of API for gathering data, and given all of the methods of bypass that exist (captcha solvers etc.) I would say that in most cases of scraping, the goal is to intentionally disregard what the website wants you to do


Upvote
13

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
I actually purposely set up my tests to go in order, I do look for the robots.txt first. But you are right, what you are saying is that I disregard the robots.txt anyway. I should create a for --force flag instead, thanks for the suggestion!


Upvote
2

Downvote

Reply

Award

Share

__EveryNameIsTaken
‚Ä¢
2mo ago
That's amazing. Knowing the amount of effort it will take to scrape a website is a time saver.


Upvote
4

Downvote

Reply

Award

Share

nemom
‚Ä¢
2mo ago
gocomics recently jumped up a level of complexity. I used to scrape the five comics I like into a single page. They've gone to a page requiring Javascript to get the content. Not an insurmountable task in Python, but I don't have time for it at the moment.



Upvote
6

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
My tool only gives you suggestions on how to workaround certain blocks that websites have like JavaScript. For example, if all they have is JavaScript rendering, then you can just use Playwright (which is also a dependency that‚Äôs automatically downloaded with caniscrape). I can‚Äôt do the hard work for you, but I can tell you how to make that work easier and save time


Upvote
3

Downvote

Reply

Award

Share


AstroPhysician
‚Ä¢
2mo ago
u/admin_PureWL avatar
u/admin_PureWL
‚Ä¢
Promoted

Monetize the VPN boom by launching your own branded VPN powered by PureVPN‚Äôs 18-year enterprise-grade infrastructure.
Monetize the VPN boom by launching your own branded VPN powered by PureVPN‚Äôs 18-year enterprise-grade infrastructure.
Monetize the VPN boom by launching your own branded VPN powered by PureVPN‚Äôs 18-year enterprise-grade infrastructure.
Monetize the VPN boom by launching your own branded VPN powered by PureVPN‚Äôs 18-year enterprise-grade infrastructure.
purevpn.com
Contact Us
u/VineMapper avatar
VineMapper
‚Ä¢
2mo ago
I webscrape alot for my maps, I'll try this out


Upvote
3

Downvote

Reply

Award

Share

u/JackedIvyLeaguer avatar
JackedIvyLeaguer
‚Ä¢
2mo ago
Hmm idk about this, its probably not a 10/10 but Amazon will 100% implement multiple different strategies to block bots if you scrape it repeatedly from the same ip, and your website is giving it a score of 0/10



Upvote
3

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Results can vary between runs because bot protections adapt dynamically.
Some heavy-protection sites (like Amazon) may produce these varied results. Of course, this will improve over time, but running the command multiple times can mitigate this.

I wrote this in the post, I know its a problem I have to fix. I'm gonna continue to keep working on it and make it more accurate.

tbh amazon bot protections is likely 9 or 10/10, just cuz they're essentially the largest online retailer, and competition is fierce. They have so many unorthodox bot protections that its just showing up as a 0


Upvote
1

Downvote

Reply

Award

Share

u/Agitated-Sherbet6442 avatar
Agitated-Sherbet6442
‚Ä¢
1mo ago
Same boat here, u/JackedIvyLeaguer. Amazon showed 0/10 for me too until I ran the check behind a residential hop. Turns out caniscrape sees a datacenter IP and shrugs, but the moment you hit it from a ‚Äòreal‚Äô home IP the WAF rules crank up and the score spikes. I‚Äôve been testing with MagneticProxy (rotates legit household IPs, sticky option for login flows) and the diff is wild. There‚Äôs a free 100req tier if you just wanna experiment. Let me know if that flips your numbers üëÄ


Upvote
1

Downvote

Reply

Award

Share

Apuleius_Ardens7722
‚Ä¢
2mo ago
Can you include proof of work WAFs like Anubis, Cerberus (which is itself based on Anubis) in your python script?



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
I checked wafw00f docs (which is what I use for WAF scanning) and it seems Anubis or Cerebrus isn't supported. I'll likely have to manually add support for missing WAFs as people request it.


Upvote
1

Downvote

Reply

Award

Share

u/stranger_synchs avatar
stranger_synchs
‚Ä¢
2mo ago
Awesome


Upvote
2

Downvote

Reply

Award

Share

LoveThemMegaSeeds
‚Ä¢
2mo ago
Does using the tool on the website blow your cover? I mean suppose you must login to view any of the data



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
You will be able to log into the website with any account you want (whether you want it to represent you or not). The only way your "cover can be blown" is using your personal IP, which you can mask using a VPN or proxy rotation. Hope that helps!


Upvote
1

Downvote

Reply

Award

Share

a_v-w
‚Ä¢
2mo ago
This is great OP, I just happened to see this yesterday and then had a potential scraping project come up today.

Of 6 sites I was looking at your tool (in python, I haven't tried your website yet) identified 4 sites with reCAPTCHA protection but manual testing revealed the CAPTCHA was dormant - all sites were accessible with simple requests. This false positive actually worked in our favor by making us proceed more cautiously.

In your experience, when sites show CAPTCHA in scans but don't enforce it during normal access, what are the most common reasons? Are there specific patterns that distinguish 'decorative' CAPTCHA from actively enforced protection?

Thanks for building this - I love the proactive reconnaissance approach.



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
It‚Äôs actually crazy to think about, but websites have invisible captchas. They determine whether you ‚Äúseem‚Äù like a bot first and then serve you the captcha. The thing is, these always have to present in the website which is why my tool can detect them but you don‚Äôt see it, unless you manually trigger the rate limit or click really fast on stuff, etc.



Upvote
1

Downvote

Reply

Award

Share

a_v-w
‚Ä¢
2mo ago
Ah ok got it, now I know what to research next. Thanks.


Upvote
1

Downvote

Reply

Award

Share

boss5667
‚Ä¢
2mo ago
I am actually working on a project where I ran into a wall with a site. The pip package is what worked for me in the end as the site was giving me a rate limit error.



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Yeah, the website has some bad limitations that aren't present when running locally. I'm working on it right now but I'm glad the CLI worked for you!


Upvote
1

Downvote

Reply

Award

Share

u/primeclassic avatar
primeclassic
‚Ä¢
2mo ago
Thanks for the Tool üòä



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Thanks, I‚Äôm still working on making it better!


Upvote
1

Downvote

Reply

Award

Share

u/Illustrious_Ebb_719 avatar
Illustrious_Ebb_719
‚Ä¢
1mo ago
Wow that's so cool! i like the website graphics right way. This is a solid way to start man; you don't know how helpful and impactful your website will be in 1 to 3 years. Now some people will be able to double check URLs and know stuffs before proceeding. Honestly i love your work so keep improving from the feedback.



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
1mo ago
Thank you so much lol, I know it‚Äôs gonna take time but I‚Äôm sure it‚Äôll get better over the years, I‚Äôm still constantly trying to improve it. Thanks for the support!


Upvote
2

Downvote

Reply

Award

Share

CraigAT
‚Ä¢
2mo ago
It would be great if you could allow the results to be emailed or submitted to a central place, where they could be collated and displayed to a website (that also advertises a download link for your program - for more "individual" results).

Note this feature to upload/send in results in should 100% be an opt-in option.



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Yeah this likely seems like a thing to add to the web-ui version of caniscrape, ill keep this in mind. You're describing an API right? Like where you can continuously pull data from your specific dataset?



Upvote
1

Downvote

Reply

Award

Share

CraigAT
‚Ä¢
2mo ago
No. I mean when someone runs your program and gets results, they get an option to upload or email the results for that website to you (or some collector service - that could be an API with PUT command or a manual extraction of the data from an email, which you place into a DB).

You can then have a website that allows users to enter a domain or URL, that queries against your API/DB, giving the user results of users' various tests run against that site (with dates). Alongside those results, you could display the option to download your program - so the user can provide their own results or to "survey" more sites.



Upvote
1

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Ah so you mean like test against the history of a website. I could integrate that into my website itself no? Or do you not think that's the right call. Just whenever the user opts in to adding their data to the large "aggregate" of that specific site, I can display your results currently as well as what people have done in the past. Yeah that's a great idea and it'll keep you up to date and how often a website changes their defenses.


Upvote
2

Downvote

Reply

Award

Share

u/Key-Boat-7519 avatar
Key-Boat-7519
‚Ä¢
2mo ago
Opt-in result uploads plus a simple public dashboard/API would make this way more useful and trustworthy.

Capture a minimal JSON on submit: eTLD+1, optional path hash, timestamp, country/ASN, proxy type (residential/datacenter/mobile), browser/OS, caniscrape and Playwright versions, headless yes/no, signals found (WAF vendor, captcha type, JS challenge, rate-limit window, HTTP codes), and retries. Strip cookies, query params, and any tokens; hash client IP but keep ASN. Version every field so results are comparable across releases.

On the backend, dedupe by domain+version+signal set, weight by sample size, and show a confidence score. Surface a timeline per domain so people can see when protections changed, plus a matrix view by proxy type and browser mode. For the MVP: POST /v1/runs with an API key and HMAC to prevent spam; accept an email fallback that attaches the same JSON. Add basic moderation and throttle per source.

I use Scrapy Cloud for scheduled crawls and Bright Data to compare proxy categories, and DomainGuard when I need alerts on WAF/captcha flips across domains.

Ship opt-in uploads, a public dashboard, and versioned, anonymized telemetry, and this becomes a go-to pre-scrape check.



Upvote
2

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
Damn I just saw this, thanks for putting so much effort into the comment. Ill definitely add all of that. I'm lowkey taking a break from the website for right now though, maybe like a week, to actually ship v1.0.0 of the CLI (which is what I use on the backend of the website anyway so it benefits that as well). I don't think I can work on the website until I resolve the main challenge of accurately describing big names like Amazon and YouTube, but I'm working on an AI that will be able to prove to users that they are indeed using behavioral detection. I have already added detection for enterprise bot detection services/canvas fingerprinting as well as browser integrity analysis (to see if the JS has been tampered with) in v0.3.0. But as soon as I get this down, I'll for sure add everything you just said.


Upvote
1

Downvote

Reply

Award

Share

pspahn
‚Ä¢
2mo ago
Thanks for posting this. I went through your repo to look at the ways you are detecting a few things and have already made some server-side changes to my site to provide bogus results to your users.


Upvote
1

Downvote

Reply

Award

Share

u/LebronManning avatar
LebronManning
‚Ä¢
2mo ago
bruh it says FB is easy to scrape lmfao. u cant even login



Upvote
0

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
My tool provides details on scraping purely by if they have bot protections on the URL you gave. Yeah, that's the thing, I can't simulate a login (at least not yet). I'm gonna keep working on it to make it better.


Upvote
1

Downvote

Reply

Award

Share


Crazyboreddeveloper
‚Ä¢
2mo ago
u/asevans48 avatar
asevans48
‚Ä¢
2mo ago
The truth is you can break almost all of it. Whether its mimmicking human behavior to trick cloudflare, busting is it came with opencv, tesseract and opencv for entry, gemini or claude for tougher problems , or a million tiny hands solving the worst captchas, its all doable. Take out llms and add in machine learning and you have first job way back in 2014.


Upvote
1

Downvote

Reply

Award

Share

u/jampman31 avatar
jampman31
‚Ä¢
2mo ago
Would be cool if it also checked for rate limits or if the site blocks scrapers by IP



Upvote
1

Downvote

Reply

Award

Share

u/CrroakTTV avatar
CrroakTTV
OP
‚Ä¢
2mo ago
The site does also check for rate limits, but I lowkey have to adjust the way it does it cuz most websites have a request limit rather than a rate limit. Also websites don‚Äôt really block IPs unless they‚Äôre really suspicious, like it doesn‚Äôt seem like someone would logically access their website with that IP.


Upvote
1

Downvote

Reply

Award

Share

u/Typical-Section5392 avatar
Typical-Section5392
‚Ä¢
1mo ago
THIS IS CRAZYYY


Upvote
1

Downvote

Reply

Award

Share

u/Ok_Success9049 avatar
Ok_Success9049
‚Ä¢
1mo ago
Good for my projet scrappin webcam. ;)


Upvote
1

Downvote

Reply

Award

Share

u/Hopeful-Pie7809 avatar
Hopeful-Pie7809
‚Ä¢
1d ago
u√©, √© tudo pago, nem uma amostrinha gratis, quem tiver o plano joga o https://downdetector.com.br/ la pessoal e me falem porfa


Upvote
1

Downvote

Reply

Award

Share

Community Info Section
r/Python
pythonLogo
Join
Python
The official Python community for Reddit! Stay up to date with the latest news, packages, and meta information relating to the Python programming language. --- If you have questions or are new to Python use r/LearnPython

Show more
Created Jan 25, 2008
Public

Community Guide
213K
Pythonistas
1.8K
Weekly contributions
User flair
u/Life_Bag_7583 avatar
Life_Bag_7583
Community Bookmarks

Python.org
Daily megathreads
Python Discord
r/Python Rules
1
"How do I", Help, or similar questions belong in r/LearnPython
2
Posts must be relevant to the Python Programming Language
3
When posting projects please include both description text and a link to source code
4
Project posts must use showcase flairs and must be text
5
Submissions must be descriptive
6
No Paywalled Content
7
No Banned Links
8
Non-English Language
9
Please don't downvote without commenting your reasoning for doing so
10
Showcases must include required sections
11
No overdone or low quality AI showcases
Search by Flair
Discussion
Resource
Meta
emoji:pythonLogo: Daily Thread
emoji:pythonLogo: Official Event
Showcase
News
Tutorial
emoji:pythonLogo: Official PyCon
Events
PyData Global 2025
December 9, 2025
Online
Python Devroom @ FOSDEM 2026
January 31, 2026
Brussels, Belgium
PyCon Namibia 2026
February 20, 2026
Windhoek, Namibia
PyCascades 2026
March 20, 2026
Vancouver, British Columbia, Canada
PyCon DE & PyData 2026
April 13, 2026
Darmstadt, Germany
Join the Python Discord

Related Python communities
r/madeinpython icon
r/madeinpython
25,591 members
r/learnpython icon
r/learnpython
978,969 members
r/PythonJobs icon
r/PythonJobs
32,181 members
r/pythontips icon
r/pythontips
143,043 members
Job Board
Python job board
Python job board
Resources
Books
Automate the Boring Stuff with Python
Think Python
Fluent Python
The Quick Python Book, 4ed.
Learning
Learn Python on Excercism
Invent Your Own Computer Games with Python
PyMotW: Python Module of the Week
Beginner's Guide Reference
Five life jackets to throw to the new coder (things to do after getting a handle on python)
Full Stack Python
Learn By Example "I know Python basics, what next?" blog post
Test-Driven Development with Python
Program Arcade Games
Python for Scientists and Engineers
Dan Bader's Tips and Trickers
JetBrain's "What does this package do?" series on YouTube
Cheatsheets
Python Cheatsheet
Python Crash Course cheatsheet
Scientific Python cheatsheet
Python RegEx cheatsheet
PyDis
Python Discord Resources
Python Discord's YouTube channel
Moderators
Message Mods
u/xelf 
emoji:pythonLogo:
u/monorepo 
emoji:pythonLogo: PSF Staff | 
emoji:litestar-logo: Litestar Maintainer
Monorepo
u/ivosaurus avatar
u/ivosaurus 
pip'ing it up
u/Im__Joseph avatar
u/Im__Joseph 
emoji:python_discord: Python Discord Staff
Joe
u/Kutiekatj9 avatar
u/Kutiekatj9 
emoji:python_discord: Python Discord Staff
u/BioGeek avatar
u/BioGeek 
Bioinformatics software developer
u/nevare avatar
u/nevare
u/chromakode avatar
u/chromakode
u/mdipierro avatar
u/mdipierro
u/quasarj avatar
u/quasarj
View all moderators
Reddit Rules